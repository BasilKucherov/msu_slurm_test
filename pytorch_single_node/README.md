# PyTorch на SLURM с использованием NVIDIA Enroot контейнера

В этом репозитории представлен простой пример обучения свёрточной нейронной сети на наборе данных MNIST с помощью PyTorch и Slurm. Пример специально разработан для запуска на GPU-кластере с использованием NVIDIA Enroot контейнера.

## Предварительные требования
- Доступ к кластеру HPC с менеджером задач **Slurm**
- Поддержка контейнеров **Enroot**
- GPU с поддержкой CUDA
- Общая файловая система (`/scratch/$USER/`) для хранения данных и кода

## Структура репозитория
```
pytorch_single_node/
├── train_mnist.py          # Скрипт для обучения CNN на MNIST
├── single_node.slurm       # Скрипт Slurm для запуска на одном узле
├── resume_training.slurm   # Скрипт Slurm для возобновления обучения
└── README.md               # Этот файл
```

---

## **1. Скрипт обучения PyTorch**

Скрипт `train_mnist.py` реализует обучение простой свёрточной нейронной сети на наборе данных MNIST. Основные особенности:

- Использует PyTorch для обучения CNN
- Сохраняет чекпоинты для возможности продолжить обучение
- Логирует прогресс обучения
- Поддерживает GPU и CPU режимы
- Позволяет настроить гиперпараметры обучения через аргументы командной строки

### **Основные аргументы**
- `--batch-size`: размер батча для обучения (по умолчанию 64)
- `--epochs`: количество эпох обучения (по умолчанию 10)
- `--lr`: скорость обучения (по умолчанию 1.0)
- `--checkpoint-dir`: директория для сохранения чекпоинтов
- `--resume`: имя файла чекпоинта для продолжения обучения
- `--data-dir`: путь к директории для хранения набора данных MNIST

---

## **2. Настройка путей для данных**

В скриптах SLURM вы можете изменить следующие переменные для настройки путей:

```bash
DATA_DIR="/scratch/${USER}/datasets/mnist"

CONTAINER_DATA_DIR="/workspace/datasets/mnist"
```

Директории будут автоматически созданы при запуске скрипта, если они не существуют.

---

## **3. Запуск на одном узле с несколькими GPU**

После клонирования репозитория в директорию `/scratch/$USER/msu_slurm_test/`, вы можете запустить обучение на одном узле с несколькими GPU, используя:

```bash
cd /scratch/$USER/msu_slurm_test/pytorch_single_node
sbatch single_node.slurm
```

Этот скрипт:
- запрашивает 1 узел с 4 GPU
- монтирует директорию `/scratch/$USER/` в `/workspace` внутри контейнера
- создаёт директории для данных и чекпоинтов
- запускает обучение с заданными параметрами

### **Проверка результатов выполнения**
```bash
cat pytorch_mnist_<job_id>.out
```

---

## **4. Возобновление обучения из чекпоинта**

Если обучение было прервано или вы хотите продолжить его с использованием сохраненного чекпоинта:

```bash
cd /scratch/$USER/msu_slurm_test/pytorch_single_node
# Отредактируйте CHECKPOINT_FILE в resume_training.slurm, если нужно
sbatch resume_training.slurm
```

Этот скрипт:
- загружает состояние модели и оптимизатора из указанного чекпоинта
- продолжает обучение с того места, где оно было остановлено
- использует те же параметры настройки GPU и монтирования директорий

---

## **Полезные команды**
- `squeue -u $USER` - список всех запущенных Ваших работ
- `sinfo` - информация о доступных узлах и разделах
- `scontrol show job <jobid>` - подробная информация о задании
- `scancel <jobid>` - отмена задания

---

## **Советы по производительности**
1. Увеличьте размер батча для лучшего использования GPU
2. При наличии нескольких GPU, можно использовать распределенное обучение через `torch.distributed`
3. Для больших датасетов используйте увеличение размера `--cpus-per-task` для ускорения загрузки данных
4. Регулярно сохраняйте чекпоинты (каждые несколько эпох), чтобы не потерять прогресс обучения 
